{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ClariQ_Baseline_BM25",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/moli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/moli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def stem_tokenize(text, remove_stopwords=True):\n",
    "  stemmer = PorterStemmer()\n",
    "  tokens = [word for sent in nltk.sent_tokenize(text) \\\n",
    "                                      for word in nltk.word_tokenize(sent)]\n",
    "  tokens = [word for word in tokens if word not in \\\n",
    "          nltk.corpus.stopwords.words('english')]\n",
    "  return [stemmer.stem(word) for word in tokens]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Files paths\n",
    "\n",
    "multi_turn_request_file_path = '../data/dev_synthetic.pkl'\n",
    "question_bank_path = '../data/question_bank.tsv'\n",
    "run_file_path = '../sample_runs/dev_bm25_multi_turn'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M13NOK7Kytuv",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "outputId": "ded6d015-5413-41b0-ec24-ed91c9440a98"
   },
   "source": [
    "# Reads files and build bm25 corpus (index)\n",
    "with open(multi_turn_request_file_path, 'rb') as fi:\n",
    "    dev = pickle.load(fi)\n",
    "question_bank = pd.read_csv(question_bank_path, sep='\\t').fillna('')\n",
    "\n",
    "question_bank['tokenized_question_list'] = question_bank['question'].map(stem_tokenize)\n",
    "question_bank['tokenized_question_str'] = question_bank['tokenized_question_list'].map(lambda x: ' '.join(x))\n",
    "\n",
    "bm25_corpus = question_bank['tokenized_question_list'].tolist()\n",
    "bm25 = BM25Okapi(bm25_corpus)"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Reads the dev file and create the context_dict to make predictions\n",
    "context_dict = dict()\n",
    "for rec_id in dev:\n",
    "    ctx_id = dev[rec_id]['context_id']\n",
    "    if ctx_id not in context_dict:\n",
    "        context_dict[ctx_id] = {'initial_request': dev[rec_id]['initial_request'],\n",
    "                                'conversation_context': dev[rec_id]['conversation_context']}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mG4IWxSfytpT",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Runs bm25 for every query and stores output in file.\n",
    "\n",
    "def build_query(context_info):\n",
    "    query_str = context_info['initial_request']\n",
    "    for ctx in context_info['conversation_context']:\n",
    "        query_str += ctx['question'] + ' ' + ctx['answer']\n",
    "    return query_str\n",
    "\n",
    "def select_no_duplicate_questions(bm25_q_list, conv_context):\n",
    "    prev_questions = [x['question'] for x in conv_context]\n",
    "    bm25_preds = question_bank.set_index('tokenized_question_str').loc[bm25_q_list, 'question'].tolist()\n",
    "    pred_list = []\n",
    "    for q in bm25_preds:\n",
    "        if q not in prev_questions:\n",
    "            pred_list.append(q)\n",
    "    return pred_list\n",
    "\n",
    "with open(run_file_path, 'w') as fo:\n",
    "  for ctx_id in context_dict:\n",
    "    query = build_query(context_dict[ctx_id])\n",
    "    bm25_ranked_list = bm25.get_top_n(stem_tokenize(query, True), \n",
    "                                    bm25_corpus,\n",
    "                                    n=5)\n",
    "    bm25_q_list = [' '.join(sent) for sent in bm25_ranked_list]\n",
    "    preds = select_no_duplicate_questions(bm25_q_list, context_dict[ctx_id]['conversation_context'])\n",
    "    for i, qid in enumerate(preds):\n",
    "        fo.write('{} 0 \"{}\" {} {} bm25_multi_turn\\n'.format(ctx_id, qid, i, len(preds)-i))\n",
    "        break # we write only one result per context."
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hh-2P1kJ5Gp2",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "outputId": "66540c57-be2d-46f6-a9cc-e44d95d2fbad"
   },
   "source": [
    "! python clariq_eval_tool.py    --eval_task document_relevance\\\n",
    "                                --data_dir ../data/ \\\n",
    "                                --multi_turn \\\n",
    "                                --experiment_type dev \\\n",
    "                                --run_file {run_file_path} #\\\n",
    "                                # --out_file {run_file_path}.eval"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG1: 0.21898645957785742\r\n",
      "NDCG3: 0.201618860054938\r\n",
      "NDCG5: 0.19652670322787674\r\n",
      "NDCG10: 0.1856817702651898\r\n",
      "NDCG20: 0.17112798502504814\r\n",
      "P1: 0.2747245453338643\r\n",
      "P3: 0.2423116067082614\r\n",
      "P5: 0.2295632550112837\r\n",
      "P10: 0.2003849727864065\r\n",
      "P20: 0.15768949953537767\r\n",
      "MRR100: 0.35986740195719213\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "29kHe2dQ5JWV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}